{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'empo_1': {'Free-living': 0, 'Host-associated': 1},\n",
       " 'empo_2': {'Non-saline': 0, 'Saline': 1, 'Animal': 2, 'Plant': 3},\n",
       " 'empo_3': {'Water (non-saline)': 0,\n",
       "  'Soil (non-saline)': 1,\n",
       "  'Sediment (saline)': 2,\n",
       "  'Animal surface': 3,\n",
       "  'Surface (non-saline)': 4,\n",
       "  'Animal distal gut': 5,\n",
       "  'Animal corpus': 6,\n",
       "  'Plant surface': 7,\n",
       "  'Water (saline)': 8,\n",
       "  'Animal secretion': 9,\n",
       "  'Sediment (non-saline)': 10,\n",
       "  'Plant rhizosphere': 11,\n",
       "  'Plant corpus': 12,\n",
       "  'Surface (saline)': 13,\n",
       "  'Animal proximal gut': 14,\n",
       "  'Aerosol (non-saline)': 15,\n",
       "  'Hypersaline (saline)': 16}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs = pd.read_csv('training_environments.csv', index_col=0)\n",
    "empo_names = [f'empo_{i}' for i in range(1, 4)]\n",
    "empo_index_to_label = []\n",
    "\n",
    "for empo in empo_names:\n",
    "    empo_index_to_label.append([str(row) for row in envs.drop_duplicates(subset=empo)[empo]])\n",
    "    \n",
    "empo_label_to_index = {name : {label : i for i, label in enumerate(labels)} for name, labels in zip(empo_names, empo_index_to_label)}\n",
    "empo_label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace text labels with integers\n",
    "envs = envs.replace(empo_label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_sparse(in_filename, out_filename):\n",
    "    line_count = sum(1 for line in open(in_filename))\n",
    "    rows = []\n",
    "    with open(in_filename) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            row = [int(x) for x in line.strip().split(',')[1:]]\n",
    "            row = sps.csr_matrix(row)\n",
    "            rows.append(row)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f'Sparsifying {in_filename} [row {i} / {line_count}]\\r')\n",
    "    mat = sps.vstack(rows)\n",
    "    \n",
    "    sps.save_npz(out_filename, mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def maybe_sparsify(in_filename, out_filename):\n",
    "    if not Path(out_filename).is_file():\n",
    "        save_as_sparse(in_filename, out_filename)\n",
    "    \n",
    "maybe_sparsify('training_descriptors.csv', 'training_descriptors_sparse.npz')\n",
    "maybe_sparsify('challenge_descriptors.csv', 'challenge_descriptors_sparse.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = sps.load_npz('training_descriptors_sparse.npz')\n",
    "\n",
    "gen = np.random.default_rng(0)\n",
    "\n",
    "n_samples = desc.shape[0]\n",
    "idx = np.arange(n_samples)\n",
    "\n",
    "gen.shuffle(idx)\n",
    "desc_shuf = desc[idx]\n",
    "envs_shuf = envs.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pcent = .8\n",
    "train_count = int(round(train_pcent * n_samples))\n",
    "\n",
    "desc_train = desc_shuf[:train_count]\n",
    "desc_validate = desc_shuf[train_count:]\n",
    "\n",
    "envs_train = envs_shuf[:train_count]\n",
    "envs_validate = envs_shuf[train_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_score(empo, samples=None):\n",
    "    clf = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    clf.fit(desc_train[:samples], envs_train[empo][:samples])\n",
    "    \n",
    "    return clf.score(desc_validate, envs_validate[empo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9614010007147963"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_score('empo_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9556826304503216"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_score('empo_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313795568263045"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_score('empo_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
