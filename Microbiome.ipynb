{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling : sparsify, use indices for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse as sps\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = pd.read_csv('training_environments.csv', index_col=0)\n",
    "empo_names = [f'empo_{i}' for i in range(1, 4)]\n",
    "empo_index_to_label = []\n",
    "\n",
    "for empo in empo_names:\n",
    "    empo_index_to_label.append([str(row) for row in envs.drop_duplicates(subset=empo)[empo]])\n",
    "    \n",
    "empo_label_to_index = {name : {label : i for i, label in enumerate(labels)} for name, labels in zip(empo_names, empo_index_to_label)}\n",
    "empo_label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace text labels with integers\n",
    "envs = envs.replace(empo_label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_sparse(in_filename, out_filename):\n",
    "    line_count = sum(1 for line in open(in_filename))\n",
    "    rows = []\n",
    "    with open(in_filename) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            row = [int(x) for x in line.strip().split(',')[1:]]\n",
    "            row = sps.csr_matrix(row)\n",
    "            rows.append(row)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f'Sparsifying {in_filename} [row {i} / {line_count}]\\r')\n",
    "    mat = sps.vstack(rows)\n",
    "    \n",
    "    sps.save_npz(out_filename, mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def maybe_sparsify(in_filename, out_filename):\n",
    "    if not Path(out_filename).is_file():\n",
    "        save_as_sparse(in_filename, out_filename)\n",
    "        \n",
    "def get_header_line(csv_file):\n",
    "    with open(csv_file) as f:\n",
    "        line = next(f)\n",
    "        return np.array(line.rstrip().split(',')[1:])\n",
    "    \n",
    "maybe_sparsify('training_descriptors.csv', 'training_descriptors_sparse.npz')\n",
    "maybe_sparsify('challenge_descriptors.csv', 'challenge_descriptors_sparse.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_species_names = get_header_line('training_descriptors_header.csv')\n",
    "\n",
    "desc = sps.load_npz('training_descriptors_sparse.npz')\n",
    "species = pd.read_csv('bacterial_species.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(desc_species_names, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_megabytes(a):\n",
    "    return (a.data.nbytes + a.indptr.nbytes + a.indices.nbytes) / (1024 * 1024)\n",
    "\n",
    "print(f'In-memory size of desc : {sparse_megabytes(desc):.2f}M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_taxonomy_df(desc, taxon_level):\n",
    "    taxons = species[taxon_level][desc_species_names]\n",
    "    columns = taxons.unique()\n",
    "\n",
    "    taxon_indices, taxon_names = pd.factorize(taxons)\n",
    "    \n",
    "    data = np.ones(taxon_indices.shape)\n",
    "    row_ind = np.arange(taxon_indices.shape[0])\n",
    "    col_ind = taxon_indices\n",
    "    \n",
    "    D = sps.csr_matrix((data, (row_ind, col_ind)))\n",
    "    \n",
    "    table = desc @ D\n",
    "    \n",
    "    return taxon_names, table\n",
    "\n",
    "taxon_names = {}\n",
    "taxons = {}\n",
    "\n",
    "for taxon_level in species.columns:\n",
    "    taxon_names[taxon_level], taxons[taxon_level] = to_taxonomy_df(desc, taxon_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "clf_logit = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "clf_rforest = RandomForestClassifier(random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_clf(clf, desc, empo, samples=None, fast=False, n_splits=5):\n",
    "    samples = samples if samples is not None else desc.shape[0]\n",
    "    \n",
    "    # shuffle and truncate data\n",
    "    idx = np.arange(samples)\n",
    "\n",
    "    gen = np.random.default_rng(0)\n",
    "    gen.shuffle(idx)\n",
    "    idx = idx[:samples]\n",
    "    \n",
    "    desc = desc[idx]\n",
    "    empo = empo[idx]\n",
    "    \n",
    "    if fast:\n",
    "        print('Warning : using fast evaluation, cross-validation turned off.')\n",
    "        \n",
    "        train_pcent = 1 - 1 / n_splits\n",
    "        train_count = int(round(train_pcent * samples))\n",
    "\n",
    "        desc_train = desc_shuf[:train_count]\n",
    "        desc_validate = desc_shuf[train_count:]\n",
    "\n",
    "        empo_train = empo[:train_count]\n",
    "        empo_validate = empo[train_count:]\n",
    "\n",
    "        clf.fit(desc_train, empo_train)\n",
    "        accuracy = clf.score(desc_validate, empo_validate)\n",
    "        accuracies = np.array([accuracy])\n",
    "        \n",
    "        f1 = f1_score(clf.predict(desc_validate), empo_validate, average='weighted')\n",
    "        f1 = np.array([f1])\n",
    "        \n",
    "        return {'test_accuracy' : accuracies, 'test_f1_weighted' : f1}\n",
    "    else:\n",
    "        # cross validation\n",
    "        k_folds = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    \n",
    "        return cross_validate(clf, desc, empo, cv=k_folds, scoring=['accuracy', 'f1_weighted'], n_jobs=-1)\n",
    "    \n",
    "def train_clf(clf, desc, envs, empo):\n",
    "    clf.fit(desc, envs[empo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "features = [(taxon_level, taxons[taxon_level]) for taxon_level in species.columns]\n",
    "features.append(('desc', desc))\n",
    "\n",
    "samples=None\n",
    "for clf_name, clf in [('rforest', clf_rforest), ('logit', clf_logit)]:\n",
    "    for empo in empo_names:\n",
    "        for feature_name, feature_vector in features:\n",
    "            print(clf_name, empo, feature_name)\n",
    "            \n",
    "            s = cross_validate_clf(clf, feature_vector, envs[empo], samples=samples)\n",
    "            s['clf_name'] = clf_name\n",
    "            s['empo'] = empo\n",
    "            s['features'] = feature_name\n",
    "        \n",
    "            scores.append(s)\n",
    "\n",
    "scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ['test_accuracy', 'score_time', 'test_f1_weighted', 'fit_time']:\n",
    "    scores[k + '_median'] = scores[k].apply(lambda x : np.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_clf(clf_logit, taxons['taxonomy_6'], envs['empo_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_level = 'taxonomy_2'\n",
    "feature_vector = taxons[tx_level]\n",
    "n_features = feature_vector.shape[-1]\n",
    "\n",
    "# D_0 : Domain\n",
    "# D_1 : ?\n",
    "# D_2 : Class\n",
    "# D_3 : Order\n",
    "# D_4 : Family\n",
    "# D_5 : ?\n",
    "# D_6 : ?\n",
    "\n",
    "clf_logit.fit(feature_vector, envs['empo_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_idx = np.argsort(clf_logit.coef_[0])\n",
    "plt.plot(range(n_features), sorted(np.log10(abs(clf_logit.coef_[0][feature_idx]))))\n",
    "plt.show()\n",
    "\n",
    "n = 50\n",
    "print(taxon_names[tx_level][feature_idx[-50:]])\n",
    "print(taxon_names[tx_level][feature_idx[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biological_interpretation(taxon_level, empo_name):\n",
    "    feature_vector = taxons[taxon_level]\n",
    "    n_features = feature_vector.shape[-1]\n",
    "\n",
    "    # D_0 : Domain\n",
    "    # D_1 : ?\n",
    "    # D_2 : Class\n",
    "    # D_3 : Order\n",
    "    # D_4 : Family\n",
    "    # D_5 : ?\n",
    "    # D_6 : ?\n",
    "\n",
    "    clf_logit.fit(feature_vector, envs[empo_name])\n",
    "    feature_order_idx = np.argsort(clf_logit.coef_, axis=0)\n",
    "    \n",
    "    print(feature_order_idx.shape)\n",
    "    print(taxon_names[taxon_level][feature_order_idx[-50:]])\n",
    "    print(taxon_names[taxon_level][feature_order_idx[:50]])\n",
    "    \n",
    "biological_interpretation('taxonomy_2', 'empo_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(desc)\n",
    "for taxonomy in list(species):\n",
    "    print(taxonomy, species[taxonomy].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "svd.fit(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_reduced = svd.transform(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_clf(clf_logit, desc_reduced, envs, 'empo_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_clf(clf_logit, desc_reduced, envs, 'empo_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_clf(clf_logit, desc_reduced, envs, 'empo_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(0, 1)\n",
    "plt.plot(svd.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(svd.components_ > 1e-6, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, mutual_info_classif\n",
    "selector = SelectKBest(mutual_info_classif, k=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "selector.fit(desc[:n], envs['empo_1'][:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_desc = sps.load_npz('challenge_descriptors_sparse.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clf(clf_logit, desc, envs, 'empo_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
